name: Test Automation Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run tests daily at 2 AM UTC
    - cron: '0 2 * * *'

jobs:
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.9, 3.10, 3.11, 3.12]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-xdist pytest-mock
    
    - name: Run unit tests with coverage
      run: |
        python -m pytest tests/test_comprehensive_unit_suite.py \
          tests/test_models.py \
          tests/test_matching_algorithms.py \
          tests/test_uzbek_normalizer_comprehensive.py \
          tests/test_config_service.py \
          tests/test_file_service.py \
          -v \
          --cov=src \
          --cov-report=xml \
          --cov-report=term-missing \
          --cov-fail-under=90 \
          --maxfail=5 \
          -n auto
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: true

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: unit-tests
    
    services:
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: 3.11
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-xdist pytest-mock
    
    - name: Run integration tests
      env:
        REDIS_URL: redis://localhost:6379
        TESTING: true
      run: |
        python -m pytest tests/test_integration_comprehensive.py \
          tests/test_api_integration.py \
          tests/test_matching_engine_integration.py \
          tests/test_result_storage_integration.py \
          -v \
          --cov=src \
          --cov-report=xml \
          --cov-append \
          --maxfail=3 \
          -n auto
    
    - name: Upload integration coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: integration
        name: codecov-integration

  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    needs: unit-tests
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: 3.11
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-benchmark pytest-xdist
    
    - name: Run performance tests
      run: |
        python -m pytest tests/test_blocking_performance.py \
          -v \
          --benchmark-only \
          --benchmark-json=benchmark.json \
          --maxfail=3
    
    - name: Store benchmark results
      uses: benchmark-action/github-action-benchmark@v1
      with:
        tool: 'pytest'
        output-file-path: benchmark.json
        github-token: ${{ secrets.GITHUB_TOKEN }}
        auto-push: true
        comment-on-alert: true
        alert-threshold: '200%'
        fail-on-alert: true

  security-tests:
    name: Security Tests
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: 3.11
    
    - name: Install security tools
      run: |
        python -m pip install --upgrade pip
        pip install bandit safety semgrep
    
    - name: Run Bandit security scan
      run: |
        bandit -r src/ -f json -o bandit-report.json
    
    - name: Run Safety check
      run: |
        safety check --json --output safety-report.json
    
    - name: Run Semgrep scan
      run: |
        semgrep --config=auto src/ --json --output=semgrep-report.json
    
    - name: Upload security reports
      uses: actions/upload-artifact@v3
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json
          semgrep-report.json

  code-quality:
    name: Code Quality
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: 3.11
    
    - name: Install quality tools
      run: |
        python -m pip install --upgrade pip
        pip install black flake8 mypy isort pylint
        pip install -r requirements.txt
    
    - name: Check code formatting with Black
      run: |
        black --check --diff src/ tests/
    
    - name: Check import sorting with isort
      run: |
        isort --check-only --diff src/ tests/
    
    - name: Run flake8 linting
      run: |
        flake8 src/ tests/ --max-line-length=100 --extend-ignore=E203,W503
    
    - name: Run mypy type checking
      run: |
        mypy src/ --ignore-missing-imports --no-strict-optional
    
    - name: Run pylint
      run: |
        pylint src/ --disable=C0114,C0115,C0116 --max-line-length=100

  test-data-validation:
    name: Test Data Validation
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: 3.11
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest
    
    - name: Validate test data generators
      run: |
        python -m pytest tests/test_data_generators.py -v
    
    - name: Generate and validate test scenarios
      run: |
        python tests/test_data_generators.py
    
    - name: Check test data cleanup
      run: |
        # Ensure no test data files are left behind
        if [ -d "test_data" ]; then
          echo "Test data directory should be cleaned up"
          exit 1
        fi

  docker-tests:
    name: Docker Tests
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Build Docker image
      run: |
        docker build -t file-processing-test .
    
    - name: Run tests in Docker
      run: |
        docker run --rm \
          -v ${{ github.workspace }}:/app \
          -w /app \
          file-processing-test \
          python -m pytest tests/test_simple_unit.py -v

  test-report:
    name: Test Report
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, performance-tests, security-tests, code-quality]
    if: always()
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Download all artifacts
      uses: actions/download-artifact@v3
    
    - name: Generate test report
      run: |
        echo "# Test Execution Report" > test-report.md
        echo "" >> test-report.md
        echo "## Test Results Summary" >> test-report.md
        echo "- Unit Tests: ${{ needs.unit-tests.result }}" >> test-report.md
        echo "- Integration Tests: ${{ needs.integration-tests.result }}" >> test-report.md
        echo "- Performance Tests: ${{ needs.performance-tests.result }}" >> test-report.md
        echo "- Security Tests: ${{ needs.security-tests.result }}" >> test-report.md
        echo "- Code Quality: ${{ needs.code-quality.result }}" >> test-report.md
        echo "" >> test-report.md
        echo "## Timestamp" >> test-report.md
        echo "Generated at: $(date -u)" >> test-report.md
    
    - name: Upload test report
      uses: actions/upload-artifact@v3
      with:
        name: test-report
        path: test-report.md
    
    - name: Comment PR with results
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          const report = fs.readFileSync('test-report.md', 'utf8');
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: report
          });

  cleanup:
    name: Cleanup
    runs-on: ubuntu-latest
    needs: [test-report]
    if: always()
    
    steps:
    - name: Cleanup old artifacts
      uses: actions/github-script@v6
      with:
        script: |
          const artifacts = await github.rest.actions.listWorkflowRunArtifacts({
            owner: context.repo.owner,
            repo: context.repo.repo,
            run_id: context.runId,
          });
          
          // Keep only the latest 10 artifacts
          const oldArtifacts = artifacts.data.artifacts
            .sort((a, b) => new Date(b.created_at) - new Date(a.created_at))
            .slice(10);
          
          for (const artifact of oldArtifacts) {
            await github.rest.actions.deleteArtifact({
              owner: context.repo.owner,
              repo: context.repo.repo,
              artifact_id: artifact.id,
            });
          }